

<!DOCTYPE html>
<html lang="en" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="John Doe">
  <meta name="keywords" content="">
  
    <meta name="description" content="Hive简介Hive的产生 Hive是基于Hadoop的一个数据仓库工具 可以将结构化的数据文件映射为一张数据库表，并提供简单的类SQL(HQL)查询功能，可以将HQL语句转换为MapReduce任务进行运行 学习成本低，可以通过类SQL语句快速实现简单的MapReduce统计，不必开发专门的MapReduce应用 适合数据仓库的ETL和统计分析 由Facebook开发并开源，贡献给Apache基">
<meta property="og:type" content="article">
<meta property="og:title" content="Hive">
<meta property="og:url" content="http://example.com/2022/08/07/%E5%A4%A7%E6%95%B0%E6%8D%AE/Hive/Hive/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="Hive简介Hive的产生 Hive是基于Hadoop的一个数据仓库工具 可以将结构化的数据文件映射为一张数据库表，并提供简单的类SQL(HQL)查询功能，可以将HQL语句转换为MapReduce任务进行运行 学习成本低，可以通过类SQL语句快速实现简单的MapReduce统计，不必开发专门的MapReduce应用 适合数据仓库的ETL和统计分析 由Facebook开发并开源，贡献给Apache基">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://fyh-blog-picture.oss-cn-hangzhou.aliyuncs.com/img/image-20220807110840522.png">
<meta property="og:image" content="https://fyh-blog-picture.oss-cn-hangzhou.aliyuncs.com/img/image-20220807111249027.png">
<meta property="og:image" content="https://fyh-blog-picture.oss-cn-hangzhou.aliyuncs.com/img/image-20220807112433376.png">
<meta property="og:image" content="https://fyh-blog-picture.oss-cn-hangzhou.aliyuncs.com/img/image-20220807112609277.png">
<meta property="og:image" content="https://fyh-blog-picture.oss-cn-hangzhou.aliyuncs.com/img/image-20220807113237738.png">
<meta property="og:image" content="https://fyh-blog-picture.oss-cn-hangzhou.aliyuncs.com/img/image-20220807113510064.png">
<meta property="og:image" content="https://fyh-blog-picture.oss-cn-hangzhou.aliyuncs.com/img/image-20220807113743626.png">
<meta property="og:image" content="https://fyh-blog-picture.oss-cn-hangzhou.aliyuncs.com/img/image-20220807152421812.png">
<meta property="og:image" content="https://fyh-blog-picture.oss-cn-hangzhou.aliyuncs.com/img/image-20220807152431062.png">
<meta property="og:image" content="https://fyh-blog-picture.oss-cn-hangzhou.aliyuncs.com/img/image-20220807152540574.png">
<meta property="og:image" content="https://fyh-blog-picture.oss-cn-hangzhou.aliyuncs.com/img/image-20220807152802384.png">
<meta property="og:image" content="https://fyh-blog-picture.oss-cn-hangzhou.aliyuncs.com/img/image-20220807152906857.png">
<meta property="og:image" content="https://fyh-blog-picture.oss-cn-hangzhou.aliyuncs.com/img/image-20220807153056352.png">
<meta property="og:image" content="https://fyh-blog-picture.oss-cn-hangzhou.aliyuncs.com/img/image-20220807153341125.png">
<meta property="og:image" content="https://fyh-blog-picture.oss-cn-hangzhou.aliyuncs.com/img/image-20220807153529363.png">
<meta property="og:image" content="https://fyh-blog-picture.oss-cn-hangzhou.aliyuncs.com/img/image-20220807153601002.png">
<meta property="og:image" content="https://fyh-blog-picture.oss-cn-hangzhou.aliyuncs.com/img/image-20220807153710283.png">
<meta property="og:image" content="https://fyh-blog-picture.oss-cn-hangzhou.aliyuncs.com/img/image-20220807153729566.png">
<meta property="og:image" content="https://fyh-blog-picture.oss-cn-hangzhou.aliyuncs.com/img/image-20220807153826974.png">
<meta property="og:image" content="https://fyh-blog-picture.oss-cn-hangzhou.aliyuncs.com/img/image-20220807153904517.png">
<meta property="og:image" content="https://fyh-blog-picture.oss-cn-hangzhou.aliyuncs.com/img/image-20220807153916735.png">
<meta property="og:image" content="https://fyh-blog-picture.oss-cn-hangzhou.aliyuncs.com/img/image-20220807153931140.png">
<meta property="og:image" content="https://fyh-blog-picture.oss-cn-hangzhou.aliyuncs.com/img/image-20220807153949060.png">
<meta property="og:image" content="https://fyh-blog-picture.oss-cn-hangzhou.aliyuncs.com/img/image-20220807154009307.png">
<meta property="og:image" content="https://fyh-blog-picture.oss-cn-hangzhou.aliyuncs.com/img/image-20220807154017150.png">
<meta property="og:image" content="https://fyh-blog-picture.oss-cn-hangzhou.aliyuncs.com/img/image-20220807154035565.png">
<meta property="og:image" content="https://fyh-blog-picture.oss-cn-hangzhou.aliyuncs.com/img/image-20220807154041752.png">
<meta property="og:image" content="https://fyh-blog-picture.oss-cn-hangzhou.aliyuncs.com/img/image-20220807154818479.png">
<meta property="og:image" content="https://fyh-blog-picture.oss-cn-hangzhou.aliyuncs.com/img/image-20220807154916620.png">
<meta property="og:image" content="https://fyh-blog-picture.oss-cn-hangzhou.aliyuncs.com/img/image-20220807155048080.png">
<meta property="article:published_time" content="2022-08-07T02:21:35.000Z">
<meta property="article:modified_time" content="2022-08-07T07:53:30.859Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://fyh-blog-picture.oss-cn-hangzhou.aliyuncs.com/img/image-20220807110840522.png">
  
  
  
  <title>Hive - Hexo</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.2","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 6.2.0"><link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
</head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 30vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>梵音海</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                Home
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                Archives
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                Categories
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                Tags
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                About
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="Hive"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          11k words
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          88 mins
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">Hive</h1>
            
            
              <div class="markdown-body">
                
                <h1 id="Hive简介"><a href="#Hive简介" class="headerlink" title="Hive简介"></a>Hive简介</h1><h2 id="Hive的产生"><a href="#Hive的产生" class="headerlink" title="Hive的产生"></a>Hive的产生</h2><ul>
<li>Hive是基于Hadoop的一个数据仓库工具</li>
<li>可以将结构化的数据文件映射为一张数据库表，并提供简单的类SQL(HQL)查询功能，可以将HQL语句转换为MapReduce任务进行运行</li>
<li>学习成本低，可以通过类SQL语句快速实现简单的MapReduce统计，不必开发专门的MapReduce应用</li>
<li>适合数据仓库的ETL和统计分析</li>
<li>由Facebook开发并开源，贡献给Apache基金会</li>
</ul>
<h2 id="Hive的特点"><a href="#Hive的特点" class="headerlink" title="Hive的特点"></a>Hive的特点</h2><p>简单易用</p>
<ul>
<li>基于SQL表达式语法，兼容大部分SQL-92语义和部分SQL-2003扩展语义</li>
</ul>
<p>可扩展</p>
<ul>
<li>Hive基于Hadoop实现，可以自由的扩展集群的规模，一般情况下不需要重启服务</li>
</ul>
<p>延展性</p>
<ul>
<li>Hive支持用户自定义函数，用户可以根据自己的需求来实现自己的函数</li>
</ul>
<p>容错性</p>
<ul>
<li>Hadoop良好的容错性，节点出现问题SQL仍可完成执行%</li>
</ul>
<h2 id="Hive适用场景"><a href="#Hive适用场景" class="headerlink" title="Hive适用场景"></a>Hive适用场景</h2><p>最佳使用场合</p>
<ul>
<li>大数据集的批处理作业，例如：网络日志分析</li>
</ul>
<p>不适用于</p>
<ul>
<li>不能在大规模数据集上实现低延迟快速的查询，例如：Hive在几百MB的数据集上执行查询一般有分钟级的时间延迟。</li>
<li>不支持联机事务处理（OLTP）<ul>
<li>Hive不提供基于行级的数据更新操作（2.0版本开始支持Update）</li>
</ul>
</li>
</ul>
<h2 id="Hive和Hadoop的关系"><a href="#Hive和Hadoop的关系" class="headerlink" title="Hive和Hadoop的关系"></a>Hive和Hadoop的关系</h2><p><img src="https://fyh-blog-picture.oss-cn-hangzhou.aliyuncs.com/img/image-20220807110840522.png" srcset="/img/loading.gif" lazyload></p>
<h1 id="Hive系统架构"><a href="#Hive系统架构" class="headerlink" title="Hive系统架构"></a>Hive系统架构</h1><ul>
<li><p>接口</p>
<ul>
<li>CLI</li>
<li>HWI</li>
<li>ThriftServer</li>
<li>JDBC&#x2F;ODBC</li>
</ul>
</li>
<li><p>元数据存储</p>
</li>
<li><p>驱动器（Driver）</p>
<ul>
<li><p>编译器</p>
</li>
<li><p>优化器</p>
</li>
<li><p>执行器</p>
</li>
</ul>
</li>
<li><p>Hadoop</p>
<ul>
<li>MapReduce计算</li>
<li>HDFS数据存储</li>
</ul>
</li>
</ul>
<p><img src="https://fyh-blog-picture.oss-cn-hangzhou.aliyuncs.com/img/image-20220807111249027.png" srcset="/img/loading.gif" lazyload></p>
<h2 id="用户接口"><a href="#用户接口" class="headerlink" title="用户接口"></a>用户接口</h2><ul>
<li>用户接口主要有三个：CLI、ThriftServer和HWI。</li>
<li>最常用的是CLI，CLI启动的时候，会同时启动一个Hive Driver。</li>
<li>ThriftServer是以Thrift协议封装的Hive服务化接口，可以提供跨语言的访问如Python、C++等，并实现了JDBC&#x2F;ODBC协议。</li>
<li>HWI提供了一个基于浏览器访问Hive的途径。</li>
</ul>
<h2 id="元数据存储"><a href="#元数据存储" class="headerlink" title="元数据存储"></a>元数据存储</h2><ul>
<li>Hive将元数据存储在数据库中，如MySQL、Oracle、Derby。</li>
<li>Hive中的元数据包括表的名字、表的列和分区及其属性、表的属性（是否为外部表等）、表的数据所在目录等。</li>
</ul>
<h2 id="驱动器（Driver）"><a href="#驱动器（Driver）" class="headerlink" title="驱动器（Driver）"></a>驱动器（Driver）</h2><ul>
<li>编译器<ul>
<li>完成词法分析、语法分析，将HQL查询解析成AST</li>
<li>AST生成逻辑执行计划</li>
<li>逻辑执行计划生成物理MR执行计划</li>
</ul>
</li>
<li>优化器<ul>
<li>对逻辑执行计划进行优化</li>
<li>对物理执行计划进行优化</li>
</ul>
</li>
<li>执行器<ul>
<li>生成的物理执行计划转变成MR Job</li>
<li>提交到Hadoop上面执行</li>
</ul>
</li>
</ul>
<h1 id="Hive原理"><a href="#Hive原理" class="headerlink" title="Hive原理"></a>Hive原理</h1><p>SQL转化为MapReduce的过程</p>
<ol>
<li><p><strong>词法语法解析</strong>: Antlr定义SQL的语法规则，完成SQL词法，语法解析，将SQL转化为抽象语法树（AST Tree）</p>
</li>
<li><p><strong>语义解析</strong>: 遍历AST Tree，抽象出查询的基本组成单元查询块（QueryBlock）</p>
</li>
<li><p><strong>生成逻辑执行计划</strong>: 遍历查询块，翻译为逻辑执行计划，Hive用操作树（OperatorTree）表示</p>
</li>
<li><p><strong>优化逻辑执行计划</strong>: 对操作树进行变换，合并不必要的操作，减少shuffle数据量，得到优化过的逻辑执行计划</p>
</li>
<li><p><strong>生成物理执行计划</strong>: 遍历操作树，翻译为MapReduce任务，即物理执行计划</p>
</li>
<li><p><strong>优化物理执行计划</strong>: 继续对物理执行计划进行变换，生成最终的MapReduce任务</p>
</li>
</ol>
<p>简单的讲，SQL在分析执行时经历如下4步：</p>
<ol>
<li><p>语法解析</p>
</li>
<li><p>元数据绑定</p>
</li>
<li><p>优化执行策略</p>
</li>
<li><p>交付执行</p>
</li>
</ol>
<h2 id="Hive编译器"><a href="#Hive编译器" class="headerlink" title="Hive编译器"></a>Hive编译器</h2><p>Parser：</p>
<ol>
<li>将SQL转换成抽象语法树</li>
</ol>
<p>语法解析器：</p>
<ol start="2">
<li>将抽象语法树转换成查询块</li>
</ol>
<p>逻辑计划生成器：</p>
<ol start="3">
<li>将查询块转换成逻辑计划</li>
</ol>
<p>逻辑计划优化器：</p>
<ol start="4">
<li>优化逻辑计划</li>
</ol>
<p>物理计划生成器：</p>
<ol start="5">
<li>将逻辑计划转换成物理计划</li>
</ol>
<p>物理计划优化器：</p>
<ol start="6">
<li>物理计划优化策略</li>
</ol>
<p><img src="https://fyh-blog-picture.oss-cn-hangzhou.aliyuncs.com/img/image-20220807112433376.png" srcset="/img/loading.gif" lazyload></p>
<h2 id="Hive实现原理"><a href="#Hive实现原理" class="headerlink" title="Hive实现原理"></a>Hive实现原理</h2><ul>
<li>Hive的编译器将HQL转换成一组操作符(Operator)</li>
<li>操作符是Hive的最小处理单元</li>
<li>每个操作符代表一道HDFS操作或者MR Job操作</li>
</ul>
<p><img src="https://fyh-blog-picture.oss-cn-hangzhou.aliyuncs.com/img/image-20220807112609277.png" srcset="/img/loading.gif" lazyload></p>
<h2 id="Hive内部操作"><a href="#Hive内部操作" class="headerlink" title="Hive内部操作"></a>Hive内部操作</h2><table>
<thead>
<tr>
<th>操作符</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>TableScanOpeator</td>
<td>扫描hive表数据</td>
</tr>
<tr>
<td>ReduceSinkOperator</td>
<td>创建发送到Reduce端的&lt;Key,Value&gt;对</td>
</tr>
<tr>
<td>JoinOperator</td>
<td>Join两份数据</td>
</tr>
<tr>
<td>SelectOperator</td>
<td>选择输出列</td>
</tr>
<tr>
<td>FileSinkOperator</td>
<td>建立结果数据，输出至文件</td>
</tr>
<tr>
<td>FilterOperator</td>
<td>过滤输入数据</td>
</tr>
<tr>
<td>GroupByOperator</td>
<td>Group By语句</td>
</tr>
<tr>
<td>MapJoinOperator</td>
<td>mapjoin语句</td>
</tr>
<tr>
<td>LimitOperator</td>
<td>Limit语句</td>
</tr>
<tr>
<td>UnionOperator</td>
<td>Union语句</td>
</tr>
</tbody></table>
<h2 id="语法解析"><a href="#语法解析" class="headerlink" title="语法解析"></a>语法解析</h2><p>语法解析之后，会形成一棵语法树，如下图所示。树中的每个节点是执行的rule,整棵树称之为执行策略。</p>
<p><img src="https://fyh-blog-picture.oss-cn-hangzhou.aliyuncs.com/img/image-20220807113237738.png" srcset="/img/loading.gif" lazyload></p>
<h2 id="元数据绑定"><a href="#元数据绑定" class="headerlink" title="元数据绑定"></a>元数据绑定</h2><p>QueryBlock中的ProductID，Name等标识符需要在Catalog里进行元数据绑定，并识别是否有效。</p>
<p>![](&#x2F;Users&#x2F;liuyi05&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;image-20220807113436378.png)</p>
<h2 id="策略优化"><a href="#策略优化" class="headerlink" title="策略优化"></a>策略优化</h2><p>形成上述的执行策略树还只是第一步，因为这个执行策略可以进行优化，所谓的优化就是对树中节点进行合并或是进行顺序上的调整。</p>
<p>以join操作为例，下图给出一个join优化的示例。A JOIN B等同于B JOIN A，但是顺序的调整可能给执行的性能带来极大的影响，下图就是调整前后的对比图。</p>
<p><img src="https://fyh-blog-picture.oss-cn-hangzhou.aliyuncs.com/img/image-20220807113510064.png" srcset="/img/loading.gif" lazyload></p>
<p>Hive中的逻辑查询优化可以大致分为以下几类：</p>
<ul>
<li>投影修剪</li>
<li>推导传递谓词</li>
<li>谓词下推</li>
<li>将Select-Select，Filter-Filter合并为单个操作</li>
<li>多路Join</li>
<li>查询重写以适应某些列值的Join倾斜</li>
</ul>
<h2 id="交付执行"><a href="#交付执行" class="headerlink" title="交付执行"></a>交付执行</h2><p>根据优化的逻辑计划（操作树）生存物理计划（mapreduce）。操作树由操作符构成</p>
<figure class="highlight axapta"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs axapta"><span class="hljs-keyword">select</span> <span class="hljs-built_in">guid</span>, <span class="hljs-keyword">count</span>(<span class="hljs-number">1</span>) <span class="hljs-keyword">from</span> behaviourlog <span class="hljs-keyword">where</span> dt=<span class="hljs-string">&#x27; 2020-09-01&#x27;</span> <span class="hljs-keyword">group</span> <span class="hljs-keyword">by</span> <span class="hljs-built_in">guid</span> limit <span class="hljs-number">10</span>;<br></code></pre></td></tr></table></figure>

<p><img src="https://fyh-blog-picture.oss-cn-hangzhou.aliyuncs.com/img/image-20220807113743626.png" srcset="/img/loading.gif" lazyload></p>
<ol>
<li><p>Antlr 生成AST, AST &#x3D;&gt; QueryBlock。</p>
</li>
<li><p>QB 里面的tableAlias &#x3D;&gt; TableScanOp。</p>
</li>
<li><p>根据Where中的谓词创建FilterOp作为TableScanOp的子节点。</p>
</li>
<li><p>根据出现的列创建selectOp，作为FilterOp的字节点。</p>
</li>
<li><p>GroupBy和聚合函数Count会在map-side进行部分聚合，创建GroupByOp作为selectOp的子节点。</p>
</li>
<li><p>添加ReduceSinkOp, 将GroupBy的列和distinct的列作为Key , 其他列作为值。</p>
</li>
<li><p>在Reduce-side同样需要添加GroupByOp用于合并前面Map-side的部分聚合。</p>
</li>
<li><p>Reduce端需要再次添加selectOp，最为SQL的输出列。</p>
</li>
<li><p>根据Limit，输出结构需要添加limitOp。</p>
</li>
<li><p>将结果写到临时目录，添加fileSinkOp。</p>
</li>
</ol>
<h1 id="Hive数据模型"><a href="#Hive数据模型" class="headerlink" title="Hive数据模型"></a>Hive数据模型</h1><p>Hive通过以下模型来组织HDFS上的数据</p>
<ul>
<li>数据库（Database）</li>
<li>表（Table）</li>
<li>分区（Partition）</li>
<li>桶（Bucket）</li>
</ul>
<h2 id="表（Table）"><a href="#表（Table）" class="headerlink" title="表（Table）"></a>表（Table）</h2><ul>
<li>Hive中的表和关系型数据库中的表在概念上很类似</li>
<li>每个表在HDFS中都有相应的目录用来存储表的数据</li>
</ul>
<h3 id="Table管理表和外表"><a href="#Table管理表和外表" class="headerlink" title="Table管理表和外表"></a>Table管理表和外表</h3><ul>
<li>根据数据是否受Hive管理，分为：<ul>
<li>Managed Table（管理表）</li>
<li>External Table（外表）</li>
</ul>
</li>
<li>区别：<ul>
<li>Managed Table：<ul>
<li>HDFS存储数据受Hive管理，在统一的路径下:${hive.metastore.warehouse.dir}&#x2F;{database_name}.db&#x2F;{tablename}</li>
<li>Hive对表的删除操作影响实际数据的删除</li>
</ul>
</li>
<li>External Table：<ul>
<li>HDFS存储路径不受Hive管理，只是Hive元数据与HDFS数据路径的一个映射</li>
<li>Hive对表的删除操作仅仅删除元数据，实际数据不受影响</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Table永久表和临时表"><a href="#Table永久表和临时表" class="headerlink" title="Table永久表和临时表"></a>Table永久表和临时表</h3><ul>
<li>Permanent Table是指永久存储在HDFS之上的表，默认创建表为永久表</li>
<li>Temporary Table是指仅当前Session有效的表，数据临时存放在用户的临时目录下，当前session退出后即删除<ul>
<li>临时表比较适合于比较复杂的SQL逻辑中拆分逻辑块，或者临时测试</li>
</ul>
</li>
<li>注意：<ul>
<li>如果创建临时表时，存在与之同名的永久表，则临时表的可见性高于永久表，即对表的操作是临时表的，用永久表无效</li>
<li>临时表不支持分区</li>
</ul>
</li>
</ul>
<h2 id="Partition"><a href="#Partition" class="headerlink" title="Partition"></a>Partition</h2><ul>
<li>基于用户指定的分区列的值对数据表进行分区</li>
<li>表的每一个分区对应表下的相应目录，所有分区的数据都是存储在对应的目录中：${hive.metastore.warehouse.dir}&#x2F;{database_name}.db&#x2F;{tablename}&#x2F;{partitionkey}&#x3D;{value}</li>
</ul>
<p>分区的优点</p>
<ul>
<li>分区从物理上分目录划分不同列的数据</li>
<li>用于查询的剪枝，提升查询的效率</li>
<li>可以多级Partition，即指定多个Partition字段，但所有Partition的数据不可无限扩展（多级目录造成HDFS小文件过多影响性能）</li>
</ul>
<h2 id="Bucket"><a href="#Bucket" class="headerlink" title="Bucket"></a>Bucket</h2><ul>
<li>桶作为另一种数据组织方式，弥补Partition的短板（不是所有的列都可以作为Partition Key）</li>
<li>通过Bucket列的值进行Hash散列到相应的文件中，重新组织数据，每一个桶对应一个文件</li>
</ul>
<p>桶的优点：</p>
<ul>
<li>有利于查询优化</li>
<li>对于抽样非常有效</li>
<li>桶的数量一旦定义后，如果更改，只会修改Hive元数据，实际数据不会重新组织</li>
</ul>
<h1 id="Hive存储模型"><a href="#Hive存储模型" class="headerlink" title="Hive存储模型"></a>Hive存储模型</h1><h2 id="列存"><a href="#列存" class="headerlink" title="列存"></a>列存</h2><ul>
<li>对增加、插入、删除、修改的事务处理I&#x2F;O高、效率低</li>
<li>非常适合做统计查询类操作，统计分析一般是针对指定列进行，只需要把指定列读取到内存进行操作</li>
</ul>
<h2 id="行存"><a href="#行存" class="headerlink" title="行存"></a>行存</h2><ul>
<li>适合增加、插入、删除、修改的事务处理处理</li>
<li>对列的统计分析却需要耗费大量的I&#x2F;O。对指定列进行统计分析时，需要把整张表读取到内存，然后再逐行对列进行读取分析操作</li>
</ul>
<h2 id="文件格式"><a href="#文件格式" class="headerlink" title="文件格式"></a>文件格式</h2><ul>
<li>Hive的数据存储在HDFS上，支持多种不同文件格式</li>
<li>在创建表时，通过STORED AS <FileFormat>语句指定存储文件格式</li>
</ul>
<table>
<thead>
<tr>
<th>文件格式</th>
<th>类型</th>
<th>存储</th>
</tr>
</thead>
<tbody><tr>
<td>TextFile</td>
<td>文本</td>
<td>行存储</td>
</tr>
<tr>
<td>SequenceFile</td>
<td>二进制</td>
<td>行存储</td>
</tr>
<tr>
<td>RCFile</td>
<td>二进制</td>
<td>列存储</td>
</tr>
<tr>
<td>ORC</td>
<td>二进制</td>
<td>列存储</td>
</tr>
<tr>
<td>Parquet</td>
<td>二进制</td>
<td>列存储</td>
</tr>
<tr>
<td>Avro</td>
<td>二进制</td>
<td>行存储</td>
</tr>
</tbody></table>
<h3 id="TextFile"><a href="#TextFile" class="headerlink" title="TextFile"></a>TextFile</h3><ul>
<li>Hive默认格式（可通过hive.default.fileformat参数定义为默认其他格式）</li>
<li>可读性好，肉眼可读</li>
<li>磁盘开销大，数据解析开销大，不建议生产系统采用这种格式</li>
<li>可以配合压缩来缓解IO压力，比如lzo&#x2F;gzip&#x2F;bzip2，但压缩后不可Split</li>
<li>对于Schema的变动支持很弱，只能在最后字段新增字段，已存在的字段无法删除</li>
</ul>
<p><img src="https://fyh-blog-picture.oss-cn-hangzhou.aliyuncs.com/img/image-20220807152421812.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://fyh-blog-picture.oss-cn-hangzhou.aliyuncs.com/img/image-20220807152431062.png" srcset="/img/loading.gif" lazyload></p>
<h3 id="SequenceFile"><a href="#SequenceFile" class="headerlink" title="SequenceFile"></a>SequenceFile</h3><ul>
<li>SequenceFile是Hadoop API提供的一种二进制文件，它将数据以&lt;key,value&gt;的形式序列化到文件中。这种二进制文件内部使用Hadoop的标准的Writable接口实现序列化和反序列化</li>
<li>Hive中的SequenceFile继承自Hadoop API的SequenceFile，它的key为空，使用value存放实际的值， 避免MR在运行map阶段的排序过程</li>
<li>相比Text更紧凑，支持Split</li>
<li>没有Metadata，只能新增字段</li>
</ul>
<p><img src="https://fyh-blog-picture.oss-cn-hangzhou.aliyuncs.com/img/image-20220807152540574.png" srcset="/img/loading.gif" lazyload></p>
<h3 id="Avro"><a href="#Avro" class="headerlink" title="Avro"></a>Avro</h3><p>Avro是一种用于支持数据密集型的二进制文件格式。它的文件格式更为紧凑，若要读取大量数据时，Avro能够提供更好的序列化和反序列化性能。并且Avro数据文件天生是带Schema定义的，所以它不需要开发者在API级别实现自己的Writable对象。最近多个Hadoop子项目都支持Avro数据格式，如Pig、Hive、Flume、Sqoop和HCatalog。</p>
<p><img src="https://fyh-blog-picture.oss-cn-hangzhou.aliyuncs.com/img/image-20220807152802384.png" srcset="/img/loading.gif" lazyload></p>
<h3 id="RCFile"><a href="#RCFile" class="headerlink" title="RCFile"></a>RCFile</h3><ul>
<li>RCFile是Hive推出的一种专门面向列的数据格式。它遵循“先按列划分，再垂直划分”的设计理念</li>
<li>当查询过程中，针对它并不关心的列时，它会在IO上跳过这些列</li>
</ul>
<p><img src="https://fyh-blog-picture.oss-cn-hangzhou.aliyuncs.com/img/image-20220807152906857.png" srcset="/img/loading.gif" lazyload></p>
<h3 id="ORC"><a href="#ORC" class="headerlink" title="ORC"></a>ORC</h3><ul>
<li>ORC（OptimizedRC File）存储源自于RCFile这种存储格式</li>
<li>ORC在压缩编码，查询性能方面相比RCFile做了很多优化</li>
<li>Metadata用protobuf存储，支持schema的变动，如新增或者删除字段</li>
</ul>
<p>![](&#x2F;Users&#x2F;liuyi05&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;image-20220807152953983.png)</p>
<h3 id="自定义格式"><a href="#自定义格式" class="headerlink" title="自定义格式"></a>自定义格式</h3><ul>
<li>除了默认的几种文件格式，用户还可以自定义文件格式</li>
<li>通过继承InputFormat和OutputFormat来自定义文件格式<ul>
<li>参考Base64InputFormat和Base64OutputFormat的实现</li>
<li><a target="_blank" rel="noopener" href="https://github.com/cloudera/hive/tree/cdh5.8.0-release/contrib/src/java/org/apache/hadoop/hive/contrib/fileformat/base64">https://github.com/cloudera/hive/tree/cdh5.8.0-release/contrib/src/java/org/apache/hadoop/hive/contrib/fileformat/base64</a></li>
</ul>
</li>
<li>创建表时指定InputFormat和OutputFormat，来读取Hive中的数据</li>
</ul>
<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs pgsql"><span class="hljs-keyword">CREATE</span> <span class="hljs-keyword">TABLE</span> base64example(<span class="hljs-type">line</span> string)<br>STORED <span class="hljs-keyword">AS</span><br>inputformat <span class="hljs-string">&#x27;org.apache.hadoop.hive.contrib.fileformat.base64.Base64TextInputFormat&#x27;</span><br>outputformat <span class="hljs-string">&#x27;org.apache.hadoop.hive.contrib.fileformat.base64.Base64TextOutputFormat&#x27;</span>;<br></code></pre></td></tr></table></figure>

<h3 id="Parquet"><a href="#Parquet" class="headerlink" title="Parquet"></a>Parquet</h3><ul>
<li>源自于Google Dremel系统，Parquet相当于Google Dremel中的数据存储引擎</li>
<li>Apache Parquet最初的设计动机是存储嵌套式数据，比如Protocolbuffer，thrift、json等，将这类数据存储成列式格式，以方便对其高效压缩和编码，且使用更少的IO操作取出需要的数据，这也是Parquet相比于ORC的优势，它能够透明地将Protobuf和thrift类型的数据进行列式存储</li>
<li>存储metadata，支持schema变更</li>
</ul>
<p><img src="https://fyh-blog-picture.oss-cn-hangzhou.aliyuncs.com/img/image-20220807153056352.png" srcset="/img/loading.gif" lazyload></p>
<p>Parquet是面向分析型业务的列式存储格式，由Twitter和Cloudera合作开发，2015年5月从Apache的孵化器里毕业成为Apache顶级项目。</p>
<p>一个Parquet文件是由一个header以及一个或多个block块组成，以一个footer结尾。header中只包含一个4个字节的数字PAR1用来识别整个Parquet文件格式。文件中所有的metadata都存在于footer中。footer中的metadata包含了格式的版本信息、schema信息、key-value paris以及所有block中的metadata信息。footer中最后两个字段为一个以4个字节长度的footer的metadata，以及同header中包含的一样的PAR1。</p>
<p><img src="https://fyh-blog-picture.oss-cn-hangzhou.aliyuncs.com/img/image-20220807153341125.png" srcset="/img/loading.gif" lazyload></p>
<h4 id="Parquet结构"><a href="#Parquet结构" class="headerlink" title="Parquet结构"></a>Parquet结构</h4><ul>
<li>Row Group：<ul>
<li>数据水平切分。</li>
</ul>
</li>
<li>Column Chunk：<ul>
<li>存储某一列数据。</li>
</ul>
</li>
<li>Page：<ul>
<li>最小逻辑存储单元。</li>
</ul>
</li>
</ul>
<p>一个File对应多个Row group；</p>
<p>一个Row group对应多个Column；</p>
<p>一个Column对应多个Page。</p>
<p>高效压缩：注意到每个Column都有一个type元数据，那么压缩算法可以通过这个属性来进行对应压缩，另外元数据中的额外k&#x2F;v对可以用于存放对应列的统计信息</p>
<p><img src="https://fyh-blog-picture.oss-cn-hangzhou.aliyuncs.com/img/image-20220807153529363.png" srcset="/img/loading.gif" lazyload></p>
<h4 id="Parquet项目结构"><a href="#Parquet项目结构" class="headerlink" title="Parquet项目结构"></a>Parquet项目结构</h4><p><img src="https://fyh-blog-picture.oss-cn-hangzhou.aliyuncs.com/img/image-20220807153601002.png" srcset="/img/loading.gif" lazyload></p>
<p>parquet-format项目定义了Parquet内部的数据类型、存储格式等。</p>
<p>parquet-mr项目完成外部对象模型与Parquet内部数据类型的映射。</p>
<p>什么是对象模型？</p>
<p>对象模型可以简单理解为内存中的数据表示，Avro、Thrift、Protocol Buffers、Hive SerDe、Pig Tuple、Spark SQL InternalRow等这些都是对象模型。</p>
<p><a target="_blank" rel="noopener" href="https://github.com/apache/parquet-mr/tree/master/parquetcolumn/src/main/java/org/apache/parquet/example">https://github.com/apache/parquet-mr/tree/master/parquetcolumn/src/main/java/org/apache/parquet/example</a></p>
<h4 id="数据模型"><a href="#数据模型" class="headerlink" title="数据模型"></a>数据模型</h4><p>Parquet格式的数据类型没有复杂的Map、List、Set等，而是使用repeated fields和groups来表示。例如List和Set可以被表示成一个repeated field，Map可以表示成一个包含有key-value对的repeated field，而且key是required的。</p>
<p><img src="https://fyh-blog-picture.oss-cn-hangzhou.aliyuncs.com/img/image-20220807153710283.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://fyh-blog-picture.oss-cn-hangzhou.aliyuncs.com/img/image-20220807153729566.png" srcset="/img/loading.gif" lazyload></p>
<h4 id="Striping-x2F-Assembly算法"><a href="#Striping-x2F-Assembly算法" class="headerlink" title="Striping&#x2F;Assembly算法"></a>Striping&#x2F;Assembly算法</h4><p>对于嵌套数据类型，我们除了存储数据的value之外还需要两个变量Repetition Level（R）,Definition Level(D) 。</p>
<h4 id="Definition-Level"><a href="#Definition-Level" class="headerlink" title="Definition Level"></a>Definition Level</h4><p>Definition level指的是截至当前位置为止，从根节点一路到此的路径上有多少可选的节点被定义了，因为是可选的，因此required类型不统计在内。</p>
<p><img src="https://fyh-blog-picture.oss-cn-hangzhou.aliyuncs.com/img/image-20220807153826974.png" srcset="/img/loading.gif" lazyload></p>
<p>Definition level的计算公式：当前树深度- 路径上类型为required的个数- 1（如果自身为null）</p>
<h4 id="Repetition-level"><a href="#Repetition-level" class="headerlink" title="Repetition level"></a>Repetition level</h4><p>针对repeated类型，它的Repetition level等于根节点到达它的路径上的repeated节点的个数。</p>
<p><img src="https://fyh-blog-picture.oss-cn-hangzhou.aliyuncs.com/img/image-20220807153904517.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://fyh-blog-picture.oss-cn-hangzhou.aliyuncs.com/img/image-20220807153916735.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://fyh-blog-picture.oss-cn-hangzhou.aliyuncs.com/img/image-20220807153931140.png" srcset="/img/loading.gif" lazyload></p>
<h4 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h4><p><img src="https://fyh-blog-picture.oss-cn-hangzhou.aliyuncs.com/img/image-20220807153949060.png" srcset="/img/loading.gif" lazyload></p>
<p>name是required的，所以既不符合定义等级，也不符合重复等级的要求，又是第一层的节点，因此全部都是0</p>
<p><img src="https://fyh-blog-picture.oss-cn-hangzhou.aliyuncs.com/img/image-20220807154009307.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://fyh-blog-picture.oss-cn-hangzhou.aliyuncs.com/img/image-20220807154017150.png" srcset="/img/loading.gif" lazyload></p>
<p>score列所处层级、类型与name列一致，也全部都是0age列同样处于第一层，但是它是optinal的，因此满足定义等级的要求，只有张三有age，定义等级为1，路径上只有它自己满足，重复等级为0</p>
<p><img src="https://fyh-blog-picture.oss-cn-hangzhou.aliyuncs.com/img/image-20220807154035565.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="https://fyh-blog-picture.oss-cn-hangzhou.aliyuncs.com/img/image-20220807154041752.png" srcset="/img/loading.gif" lazyload></p>
<h4 id="Project-Pushdown"><a href="#Project-Pushdown" class="headerlink" title="Project Pushdown"></a>Project Pushdown</h4><p>Project Pushdown意味着在获取表中原始数据时只需要扫描查询中需要的列，由于每一列的所有值都是连续存储的，所以分区取出每一列的所有值就可以实现TableScan算子，而避免扫描整个表文件内容。</p>
<p>在Parquet中原生就支持Project Pushdown，执行查询的时候可以通过Configuration传递需要读取的列的信息，这些列必须是Schema的子集，每次会扫描一个Row Group的数据，然后一次性得将该Row Group里所有需要的列的Cloumn Chunk都读取到内存中，每次读取一个RowGroup的数据能够大大降低随机读的次数。</p>
<h4 id="Predicate-Pushdown"><a href="#Predicate-Pushdown" class="headerlink" title="Predicate Pushdown"></a>Predicate Pushdown</h4><p>谓词下推是数据库最常用的优化手段，通过将过滤条件尽可能的在最底层执行可以减少数据量，从而提升性能，例如”select count(1) from A Join B on A.id &#x3D; B.id where A.a &gt; 10 and B.b &lt;100″SQL查询中，在处理Join操作之前需要首先对A和B执行TableScan操作，然后再进行Join，再执行过滤，最后计算聚合函数返回，但是如果把过滤条件A.a &gt; 10和B.b &lt; 100分别移到A表的TableScan和B表的TableScan的时候执行，可以大大降低Join操作的输入数据。</p>
<p>无论是行式存储还是列式存储，都可以在将过滤条件在读取一条记录之后执行以判断该记录是否需要返回给调用者，在Parquet做了更进一步的优化，它对每一个Row Group的每一个ColumnChunk在存储的时候都计算对应的统计信息，包括该Column Chunk的最大值、最小值和空值个数。通过这些统计值和该列的过滤条件可以判断该Row Group是否需要扫描。另外Parquet还有Bloom Filter和Index等增强谓词下推。</p>
<h1 id="Hive性能优化"><a href="#Hive性能优化" class="headerlink" title="Hive性能优化"></a>Hive性能优化</h1><h2 id="优化思路"><a href="#优化思路" class="headerlink" title="优化思路"></a>优化思路</h2><ul>
<li>编译器优化器优化<ul>
<li>采用合理的优化策略，生成高效的物理计划</li>
</ul>
</li>
<li>MapReduce执行层优化<ul>
<li>通过MR参数优化，提升Job运行效率</li>
</ul>
</li>
<li>HDFS存储层优化<ul>
<li>采用合理的存储格式和合理的Schema设计，降低IO瓶颈</li>
</ul>
</li>
</ul>
<h2 id="编译器优化器优化"><a href="#编译器优化器优化" class="headerlink" title="编译器优化器优化"></a>编译器优化器优化</h2><ul>
<li>利用Explain命令查看执行计划</li>
<li>语法：EXPLAIN [EXTENDED] query</li>
<li>输出：<ul>
<li>查询语句的抽象语法树（AST）</li>
<li>执行计划不同阶段间的依赖关系</li>
<li>每个阶段的描述</li>
</ul>
</li>
</ul>
<h3 id="SQL层优化"><a href="#SQL层优化" class="headerlink" title="SQL层优化"></a>SQL层优化</h3><ul>
<li>不必要的shuffle</li>
<li>NestLoopJoin</li>
<li>Window函数</li>
<li>全局排序</li>
<li>谓词下推异常</li>
<li>数据倾斜</li>
<li>Join顺序</li>
<li>Join膨胀</li>
<li>MapJoin</li>
<li>特殊UDF（ percentile)</li>
</ul>
<h2 id="MapReduce执行层优化"><a href="#MapReduce执行层优化" class="headerlink" title="MapReduce执行层优化"></a>MapReduce执行层优化</h2><ul>
<li>并发度控制<ul>
<li>Num_Map_tasks &#x3D; $inputsize &#x2F; max($mapred.min.split.size, min($dfs.block.size,$mapred.max.split.size))</li>
<li>Num_Reduce_tasks &#x3D; min($hive.exec.reducers.max ,$inputsize&#x2F;$hive.exec.reducers.bytes.per.reducer)</li>
</ul>
</li>
<li>Job并行执行<ul>
<li>set hive.exec.parallel&#x3D;true;</li>
</ul>
</li>
<li>Task内存优化</li>
<li>本地执行<ul>
<li>set hive.exec.mode.local.auto&#x3D;true;</li>
<li>hive.exec.mode.local.auto.inputbytes.max（默认128MB）</li>
<li>hive.exec.mode.local.auto.input.files.max（默认4）</li>
</ul>
</li>
<li>JVM重用<ul>
<li>set mapred.job.reuse.jvm.num.tasks&#x3D;10 &#x2F;&#x2F;每个jvm运行10个task</li>
</ul>
</li>
<li>推测执行<ul>
<li>set hive.mapred.reduce.tasks.speculative.execution&#x3D;true</li>
<li>set mapreduce.map.speculative&#x3D;true</li>
<li>set mapreduce.reduce.speculative&#x3D;true</li>
</ul>
</li>
<li>开启压缩<ul>
<li>中间结果压缩，减少Job跟Job之间的IO开销</li>
<li>set hive.exec.compress.intermediate&#x3D;true</li>
<li>set mapred.map.output.compression.codec&#x3D;<CodecClassName></li>
</ul>
</li>
<li>最终结果压缩，减少存储空间<ul>
<li>set hive.exec.compress.output&#x3D;true</li>
<li>set mapred.output.compression.codec&#x3D;<CodecClassName></li>
</ul>
</li>
</ul>
<h2 id="存储层优化"><a href="#存储层优化" class="headerlink" title="存储层优化"></a>存储层优化</h2><ul>
<li>列存储，高压缩比，列剪枝，过滤无用字段IO<ul>
<li>Orc</li>
<li>Parquet</li>
</ul>
</li>
<li>分区分桶</li>
<li>合并输入小文件<ul>
<li>如果Job输入有很多小文件，造成Map数太多，影响效率</li>
<li>set hive.input.format&#x3D;org.apache.hadoop.hive.ql.io.CombineHiveInputFormat</li>
</ul>
</li>
<li>小文件合并<ul>
<li>set hive.merge.mapfiles&#x3D;true; &#x2F;&#x2F; map only job结束时合并小文件</li>
<li>set hive.merge.mapredfiles&#x3D;true; &#x2F;&#x2F; 合并reduce输出的小文件</li>
<li>set hive.merge.smallfiles.avgsize&#x3D;256000000; &#x2F;&#x2F;当输出文件平均大小小于该值，启动新job合并文件</li>
<li>set hive.merge.size.per.task&#x3D;64000000; &#x2F;&#x2F;合并之后的每个文件大小</li>
</ul>
</li>
</ul>
<h2 id="Hive优化器支持的几条优化"><a href="#Hive优化器支持的几条优化" class="headerlink" title="Hive优化器支持的几条优化"></a>Hive优化器支持的几条优化</h2><ul>
<li>Limit优化<ul>
<li>查询hive数据时，用limit限制输出数据数目</li>
<li>正常情况，会执行全表查询，而只返回很少一部分数据，浪费时间和IO</li>
<li>优化手段：抽样查询，不需要进行全表查询<ul>
<li>set hive.limit.optimize.enable&#x3D;true;</li>
<li>hive.limit.row.max.size &#x2F;&#x2F;每一行最大长度</li>
<li>hive.limit.optimize.limit.file &#x2F;&#x2F;从多少个数据文件中进行抽样</li>
</ul>
</li>
<li>弊端：<ul>
<li>有些需要的数据可能被忽略掉</li>
</ul>
</li>
</ul>
</li>
<li>MapJoin优化<ul>
<li>方式一(自动判断）：<ul>
<li>set.hive.auto.convert.join&#x3D;true;</li>
<li>hive.mapjoin.smalltable.filesize &#x2F;&#x2F; 默认值是25mb, 小表小于25mb自动启动mapjoin</li>
</ul>
</li>
<li>方式二(手动显式）：<ul>
<li>select &#x2F;<em>+mapjoin(A)</em>&#x2F; f.a,f.b from A t join B f on (f.a&#x3D;t.a)</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="https://fyh-blog-picture.oss-cn-hangzhou.aliyuncs.com/img/image-20220807154818479.png" srcset="/img/loading.gif" lazyload></p>
<ul>
<li><p>BucketJoin优化</p>
<ul>
<li><p>使用方式：</p>
<ul>
<li><p>hive.optimize.bucketmapjoin&#x3D; true</p>
</li>
<li><p>和mapjoin一起工作</p>
</li>
<li><p>所有要Join的表都必须对Join key做了分桶，并且大表的桶数是小表的整数倍</p>
</li>
</ul>
</li>
<li><p>由于对表设计有太多的限制， bucket key必须是join key的子集</p>
</li>
</ul>
</li>
</ul>
<p><img src="https://fyh-blog-picture.oss-cn-hangzhou.aliyuncs.com/img/image-20220807154916620.png" srcset="/img/loading.gif" lazyload></p>
<ul>
<li><p>Skew优化</p>
<ul>
<li><p>在SQL上，一般是由于group by或者join shuffle key不均匀造成的</p>
</li>
<li><p>数据倾斜是业务数据问题导致的，如果从业务上下手避免是最好的</p>
<ul>
<li>比如由于Null值引起的，或者某一个特殊的key数据量特别大</li>
<li>先过滤掉特殊key的数据再进行处理</li>
</ul>
</li>
<li><p>Hive自身的优化方案</p>
<ul>
<li><p>由group by引起的数据倾斜：</p>
</li>
<li><p>hive.map.aggr&#x3D;true &#x2F;&#x2F;做map端预聚合</p>
</li>
<li><p>hive.groupby.skewindata &#x2F;&#x2F;将key的数据随机分发到</p>
</li>
<li><p>Reduce端做聚合，然后再起一个Job对上一步的结果做聚合</p>
</li>
<li><p>由Join引起的数据倾斜(Skew Join)</p>
</li>
<li><p>hive.optimize.skewjoin &#x3D; true</p>
</li>
<li><p>hive.skewjoin.key &#x3D; 100000 &#x2F;&#x2F; 超过阈值就判断为skew key</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="https://fyh-blog-picture.oss-cn-hangzhou.aliyuncs.com/img/image-20220807155048080.png" srcset="/img/loading.gif" lazyload></p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/" class="category-chain-item">大数据</a>
  
  
    <span>></span>
    
  <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/Hive/" class="category-chain-item">Hive</a>
  
  

  

      </span>
    
  
</span>

    </div>
  
  
</div>


              

              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2022/08/06/%E5%A4%A7%E6%95%B0%E6%8D%AE/HBase/HBase/" title="HBase">
                        <span class="hidden-mobile">HBase</span>
                        <span class="visible-mobile">Next</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;Table of Contents</p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">Keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      headingSelector : CONFIG.toc.headingSelector || 'h1,h2,h3,h4,h5,h6',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      collapseDepth   : CONFIG.toc.collapseDepth || 0,
      scrollSmooth    : true,
      headingsOffset  : -boardTop
    });
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.10/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">Blog works best with JavaScript enabled</div>
  </noscript>
</body>
</html>
