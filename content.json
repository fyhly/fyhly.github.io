{"meta":{"title":"Hexo","subtitle":"","description":"","author":"John Doe","url":"http://example.com","root":"/"},"pages":[{"title":"about","date":"2022-08-05T07:34:26.000Z","updated":"2022-08-05T07:34:26.157Z","comments":false,"path":"about/index.html","permalink":"http://example.com/about/index.html","excerpt":"","text":""},{"title":"微服务","date":"2022-08-05T08:13:12.000Z","updated":"2022-08-05T08:15:54.006Z","comments":false,"path":"categories/index.html","permalink":"http://example.com/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"MapReduce","slug":"大数据/hadoop/MapReduce","date":"2022-08-06T09:31:38.000Z","updated":"2022-08-06T10:11:20.477Z","comments":true,"path":"2022/08/06/大数据/hadoop/MapReduce/","link":"","permalink":"http://example.com/2022/08/06/%E5%A4%A7%E6%95%B0%E6%8D%AE/hadoop/MapReduce/","excerpt":"","text":"MapReduce简介 MapReduce提供简单的API，允许用户在不了解底层细节的情况下，开发分布式并行程序，利用大规模集群资源，解决传统单机无法解决的大数据处理问题 设计思想起源于Google GFS、MapReduce Paper Doug Cutting在Yahoo开发，2008年贡献给Apache基金会 MRv1组成 编程模型 运行时环境（计算框架） 设计的目的： 主要解决搜索引擎面临的海量数据处理扩展性差的问题 易于编程，简化分布式程序设计，用户只需专注于自己的应用程序逻辑实现 MapReduce编程模型 特殊的数据驱动型 分为map和reduce两个阶段 并发只在同一个作业中发生 不同作业的数据访问不需要协调 流程 map()函数以key&#x2F;value对作为输入。 产生另外一系列key&#x2F;value对作为中间输出写入本地磁盘。 MapReduce框架会自动将这些中间数据按照key值进行聚集，且key值相同的数据被统一交给reduce()函数处理。 用户可设定聚集策略，默认情况下是对key值进行哈希取模。 reduce()函数以key及对应的value列表作为输入，经合并key相同的value值后，产生另外一系列key&#x2F;value对作为最终输出写入HDFS。 数据切分（Split）作用： 按照某个策略将数据切分成若干个split，确定Map Task个数 给定某个split，能将其解析成一个个key&#x2F;value对。 如何切分（切分算法）文件切分算法主要用于确定InputSplit的个数以及每个InputSplit对应的数据段。 一个大文件会被切分成若干个InputSplit 对文件的切分是按照“固定”大小进行的，这个大小就是split size splitSize&#x3D;max{ minSize, min{ totalSize &#x2F; numSplits, blockSize } } numSplits为用户设定的Map Task个数，默认情况下是1。 minSize为Split的最小值，由配置参数确定，默认是1。 blockSize为HDFS中的block大小，默认是64MB。 一旦确定splitSize值后，将文件依次切成大小为splitSize的InputSplit 最后剩下不足splitSize的数据块单独成为一个InputSplit minSize totalSize numSplits blockSize 实际的InputSplite个数 1 250MB 1 64MB 1 32MB 250MB 5 64MB 2 32MB 250MB 2 256MB 3 130MB 1G 1 128MB 1 Split和Block的区别 Split是文件在逻辑上的划分，是程序中的一个独立处理单位，每一个split分配给一个task去处理。在实际的存储系统中并没有按split去存储。 Block是文件在物理上的划分，HDFS系统上就是按照block来存储的。一个block的多个备份存储在不同的节点上。 一个split可能包含多个block，但一个block不一定只属于一个split。比如：split1完全包含block1，部分包含block2；block2一部分属于split1，一部分属于split2。 Host选择算法 InputSplit对象包含四个属性，分别是文件名、起始位置、Split长度和节点列表；构成一个四元组&lt;file, start, length, hosts&gt;。 节点列表是关键，关系到任务的本地性（locality）。 Hadoop将数据本地性按照代价划分成三个等级：Node、Rack和Any。 所谓任务的本地性，即优先让空闲资源处理本节点上的数据，如果节点上没有可处理的数据，则处理同一个机架上的数据，最差情况是处理其他机架上的数据。 排序（Sort）MapReduce的Sort分为两种： Map Task中Spill数据的排序 数据写入本地磁盘之前，先要对数据进行一次本地排序 快排算法 排序先按照分区编号partition进行排序，然后按照key进行排序。经过排序后，数据以分区为单位聚集在一起，且同一分区内所有数据按照key有序 Reduce Task中数据排序 Reduce Task对所有数据进行排序 归并排序算法 小顶堆 Sort和Reduce可并行进行 MapReduce计算框架MapReduce 1.0MapReduce分布式计算框架： JobTracker： 负责集群资源监控和作业调度 通过心跳监控所有TaskTracker的健康状况 监控Job的运行情况、执行进度、资源使用，交由任务调度器负责资源分配 任务调度器可插拔：FIFO Scheduler、Capacity Scheduler、FIFO Scheduler TaskTracker： 具体执行Task的单元 以slot为单位等量划分本节点的资源，分为Map Slot和Reduce Slot 通过心跳周期性向JobTracker汇报本节点的资源使用情况和任务运行进度 接收JobTracker的命令执行相应的操作（启动新任务、杀死任务等） Client： 提交用户编写的程序到集群 查看Job运行状态 MapReduce原理概述 MR Job生命周期 作业提交与初始化 a. 首先JobClient将作业的相关文件上传到HDFS b. 然后JobClient通知JobTracker c. JobTracker的作业调度模块对作业进行初始化（ JobInProgress和TaskInProgress） 任务调度与监控 a. JobTracker的任务调度器（TaskScheduler）按照一定策略，将task调度到空闲的TaskTracker 任务JVM启动 a. TaskTracker下载任务所需的文件，并为每个Task启动一个独立的JVM 任务执行 a. TaskTracker启动Task，Task通过RPC将其状态汇报给TaskTracker，再由TaskTracker汇报给JobTracker 完成作业 a. 数据写到HDFS JobTracker概述JobTracker主要负责作业控制和资源管理。JobTracker会跟踪任务的执行进度、资源使用量等信息，并将这些信息告诉任务调度器，而调度器会在资源出现空闲时，选择合适的任务使用这些资源。 JobTracker采用观察者设计模式将新作业通知TaskScheduler JobTacker涉及MR生命周期的步骤有： 作业提交到JobTracker 任务的调度与监控 其中做的操作包括： a. 为作业创建JobInProgress对象 b. 检查用户是否具有指定队列的作业提交权限 c. 检查作业配置的内存使用量是否合理 d. 通知任务调度器按照一定策略调度任务* JobTracker核心功能— 作业控制JobTracker在其内部以“三层多叉树”的方式描述和跟踪每个作业的运行状态 JobTracker核心功能— 资源管理JobTracker不断接收各个TaskTracker周期性发送过来的资源量和任务状态等信息，为TaskTracker分配最合适的任务。 Hadoop引入了“slot”概念表示各个节点上的计算资源。为了简化资源管理，Hadoop将各个节点上的资源(CPU、内存和磁盘等)等量切分成若干份，每一份用一个slot表示，同时规定一个Task可根据实际需要占用多个slot。 三级调度模型： 选择一个队列 选择一个作业 选择一个任务","categories":[{"name":"大数据","slug":"大数据","permalink":"http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"hadoop","slug":"大数据/hadoop","permalink":"http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/hadoop/"}],"tags":[]},{"title":"关注","slug":"系统设计/系统设计","date":"2022-08-05T16:05:43.000Z","updated":"2022-08-05T16:06:16.399Z","comments":true,"path":"2022/08/06/系统设计/系统设计/","link":"","permalink":"http://example.com/2022/08/06/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/","excerpt":"","text":"","categories":[{"name":"系统设计","slug":"系统设计","permalink":"http://example.com/categories/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"}],"tags":[]},{"title":"分布式锁","slug":"分布式/分布式锁","date":"2022-08-05T16:03:58.000Z","updated":"2022-08-05T16:04:33.146Z","comments":true,"path":"2022/08/06/分布式/分布式锁/","link":"","permalink":"http://example.com/2022/08/06/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/","excerpt":"","text":"","categories":[{"name":"分布式","slug":"分布式","permalink":"http://example.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"分布式锁","slug":"分布式/分布式锁","permalink":"http://example.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/"}],"tags":[]},{"title":"分布式事务","slug":"分布式/分布式事务","date":"2022-08-05T16:03:55.000Z","updated":"2022-08-05T16:04:33.141Z","comments":true,"path":"2022/08/06/分布式/分布式事务/","link":"","permalink":"http://example.com/2022/08/06/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/","excerpt":"","text":"","categories":[{"name":"分布式","slug":"分布式","permalink":"http://example.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"分布式事务","slug":"分布式/分布式事务","permalink":"http://example.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/"}],"tags":[]},{"title":"分布式缓存","slug":"分布式/分布式缓存","date":"2022-08-05T16:03:52.000Z","updated":"2022-08-05T16:04:33.126Z","comments":true,"path":"2022/08/06/分布式/分布式缓存/","link":"","permalink":"http://example.com/2022/08/06/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98/","excerpt":"","text":"","categories":[{"name":"分布式","slug":"分布式","permalink":"http://example.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"分布式缓存","slug":"分布式/分布式缓存","permalink":"http://example.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98/"}],"tags":[]},{"title":"工厂模式","slug":"设计模式/工厂模式","date":"2022-08-05T16:02:36.000Z","updated":"2022-08-05T16:03:29.985Z","comments":true,"path":"2022/08/06/设计模式/工厂模式/","link":"","permalink":"http://example.com/2022/08/06/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F/","excerpt":"","text":"","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[]},{"title":"单例模式","slug":"设计模式/单例模式","date":"2022-08-05T16:02:32.000Z","updated":"2022-08-05T16:03:30.004Z","comments":true,"path":"2022/08/06/设计模式/单例模式/","link":"","permalink":"http://example.com/2022/08/06/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/","excerpt":"","text":"","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[]},{"title":"DFS","slug":"算法/DFS","date":"2022-08-05T16:02:20.000Z","updated":"2022-08-05T16:03:29.994Z","comments":true,"path":"2022/08/06/算法/DFS/","link":"","permalink":"http://example.com/2022/08/06/%E7%AE%97%E6%B3%95/DFS/","excerpt":"","text":"","categories":[{"name":"算法","slug":"算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/"}],"tags":[]},{"title":"BFS","slug":"算法/BFS","date":"2022-08-05T16:02:17.000Z","updated":"2022-08-05T16:03:30.000Z","comments":true,"path":"2022/08/06/算法/BFS/","link":"","permalink":"http://example.com/2022/08/06/%E7%AE%97%E6%B3%95/BFS/","excerpt":"","text":"","categories":[{"name":"算法","slug":"算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/"}],"tags":[]},{"title":"动态规划","slug":"算法/动态规划","date":"2022-08-05T16:01:22.000Z","updated":"2022-08-05T16:02:09.800Z","comments":true,"path":"2022/08/06/算法/动态规划/","link":"","permalink":"http://example.com/2022/08/06/%E7%AE%97%E6%B3%95/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/","excerpt":"","text":"","categories":[{"name":"算法","slug":"算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/"},{"name":"动态规划","slug":"算法/动态规划","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"}],"tags":[]},{"title":"netty","slug":"框架/netty","date":"2022-08-05T16:01:04.000Z","updated":"2022-08-05T16:02:09.756Z","comments":true,"path":"2022/08/06/框架/netty/","link":"","permalink":"http://example.com/2022/08/06/%E6%A1%86%E6%9E%B6/netty/","excerpt":"","text":"","categories":[{"name":"框架","slug":"框架","permalink":"http://example.com/categories/%E6%A1%86%E6%9E%B6/"},{"name":"Netty","slug":"框架/Netty","permalink":"http://example.com/categories/%E6%A1%86%E6%9E%B6/Netty/"}],"tags":[]},{"title":"HDFS","slug":"大数据/hadoop/HDFS","date":"2022-08-05T16:00:00.000Z","updated":"2022-08-06T10:14:08.580Z","comments":true,"path":"2022/08/06/大数据/hadoop/HDFS/","link":"","permalink":"http://example.com/2022/08/06/%E5%A4%A7%E6%95%B0%E6%8D%AE/hadoop/HDFS/","excerpt":"","text":"HDFS简介Hadoop 分布式文件系统 (HDFS) 是一种分布式文件系统，旨在在商用硬件上运行。它与现有的分布式文件系统有很多相似之处。但是，与其他分布式文件系统的区别是显著的。HDFS 具有高度容错性，旨在部署在低成本硬件上。HDFS 提供对应用程序数据的高吞吐量访问，适用于拥有大量数据集的应用程序。HDFS 放宽了一些 POSIX 要求，以支持对文件系统数据的流式访问。HDFS 最初是作为 Apache Nutch 网络搜索引擎项目的基础设施而构建的。HDFS 是 Apache Hadoop Core 项目的一部分。项目 URL 是http://hadoop.apache.org/。 HDFS架构 HDFS 1.0 组件 NameNode： 维护整个文件系统的文件目录树，文件目录的元信息和文件数据块索引 以FsImage和EditLog形式存储在本地 整个系统的单点，存在SPOF（Simple Point of Failure） SecondaryNameNode： 又名CheckPoint Node，定期合并FsImage和EditLog 不接收客户端的请求，作为NameNode的冷备 DataNode： 实际存储数据的单元 以Block为单位 数据以普通文件形式保存在本地文件系统 Client： 与HDFS交互，进行读写、创建目录、创建文件、复制、删除等操作 HDFS提供了多种客户端：命令行Shell、Java API、Thrift接口、C library、WebHDFS等 NameNode简介集群中单个NameNode的存在极大地简化了系统的架构。NameNode 是所有 HDFS 元数据的仲裁者和存储库。该系统的设计方式是用户数据永远不会流经 NameNode。 NameNode 维护文件系统命名空间。NameNode 记录对文件系统命名空间或其属性的任何更改。应用程序可以指定应该由 HDFS 维护的文件的副本数。文件的副本数称为该文件的复制因子。此信息由 NameNode 存储。 NameNode 做出有关块复制的所有决定。它定期从集群中的每个 DataNode 接收 Heartbeat 和 Blockreport。收到心跳意味着 DataNode 运行正常。Blockreport 包含 DataNode 上所有块的列表。 持久化HDFS 命名空间由 NameNode 存储。NameNode 使用称为 EditLog 的事务日志来持久记录文件系统元数据发生的每个更改。例如，在 HDFS 中创建一个新文件会导致 NameNode 将一条记录插入到 EditLog 中来表明这一点。同样，更改文件的复制因子会导致将新记录插入到 EditLog 中。NameNode 使用其本地主机操作系统文件系统中的文件来存储 EditLog。整个文件系统命名空间，包括块到文件的映射和文件系统属性，都存储在一个名为 FsImage 的文件中。FsImage 也作为文件存储在 NameNode 的本地文件系统中。 NameNode 在内存中保存了整个文件系统命名空间和文件 Blockmap 的图像。当 NameNode 启动，或者一个检查点被一个可配置的阈值触发时，它从磁盘读取 FsImage 和 EditLog，将 EditLog 中的所有事务应用到 FsImage 的内存表示中，并将这个新版本刷新到一个磁盘上的新 FsImage。然后它可以截断旧的 EditLog，因为它的事务已应用于持久 FsImage。这个过程称为检查点。检查点的目的是通过获取文件系统元数据的快照并将其保存到 FsImage 来确保 HDFS 具有文件系统元数据的一致视图。尽管读取 FsImage 是高效的，但直接对 FsImage 进行增量编辑并不高效。我们没有为每次编辑修改 FsImage，而是将编辑保存在 Editlog 中。在检查点期间，来自 Editlog 的更改将应用于 FsImage。可以在给定的时间间隔触发检查点（dfs.namenode.checkpoint.period）以秒表示，或者在累积给定数量的文件系统事务之后（dfs.namenode.checkpoint.txns）。如果设置了这两个属性，则要达到的第一个阈值会触发检查点。 DataNode 将 HDFS 数据存储在其本地文件系统中的文件中。DataNode 不了解 HDFS 文件。它将每个 HDFS 数据块存储在其本地文件系统中的单独文件中。DataNode 不会在同一目录中创建所有文件。相反，它使用启发式方法来确定每个目录的最佳文件数并适当地创建子目录。在同一目录中创建所有本地文件并不是最佳选择，因为本地文件系统可能无法有效地支持单个目录中的大量文件。当 DataNode 启动时，它会扫描其本地文件系统，生成与这些本地文件对应的所有 HDFS 数据块的列表，并将此报告发送给 NameNode。该报告称为Blockreport。 SecondaryNameNodeNameNode 将文件系统的修改存储为附加到本机文件系统文件的日志。当 NameNode 启动时，它会从映像文件 FsImage 中读取 HDFS 状态，然后应用EditLog文件中的日志。然后它将新的 HDFS 状态写入 FsImage 并使用空的EditLog开始正常操作。由于 NameNode 仅在启动期间合并 FsImage 和EditLog，因此在繁忙的集群上，EditLog文件可能会随着时间变得非常大。较大的EditLog的另一个副作用是下次重新启动 NameNode 需要更长的时间。 SecondaryNameNode 定期合并 FsImage 和EditLog，并将EditLog保持在限制范围内。它通常在与主 NameNode 不同的机器上运行，因为它的内存需求与主 NameNode 的顺序相同。 SecondaryNameNode上检查点进程的启动由两个配置参数控制。 dfs.namenode.checkpoint.period，默认设置为 1 小时，指定两个连续检查点之间的最大延迟，以及 dfs.namenode.checkpoint.txns默认设置为 100 万，定义 NameNode 上的未检查点事务的数量，这将强制执行紧急检查点，即使尚未达到检查点周期。 SecondaryNameNode 将最新的检查点存储在一个目录中，该目录的结构与主 NameNode 的目录相同。这样检查点的图像总是准备好在必要时被主 NameNode 读取。 DataNodeDataNode将每个文件存储为一系列块。复制文件的块以实现容错。 读写流程 存在的问题 NameNode SPOF，NameNode挂掉整个集群不可用 内存受限，整个集群的size受限于NameNode的内存空间大小 HDFS 2.0 HDFS 1.0 的问题 HDFS 2.0 的改进 NameNode单点问题 NameNode HA 集群受限于NameNode空间 HDFS Federation NameNode HA 两个名称节点： Active NameNode Standby NameNode 共享存储系统：实现名称节点的状态同步 ZooKeeper：确保一个名称节点在对外服务 数据节点：同时向两个名称节点汇报信息 优点：热备份，提供高可用性 不足：无法解决可扩展性、系统性能和隔离性 NameNode HA 设计思路 主备一致实现 如何保持主和备NameNode的状态同步 脑裂的解决 脑裂问题就是产生了两个leader，导致集群行为不一致了 1）仲裁：当两个节点出现分歧时，由第3方的仲裁者决定听谁的 2）fencing：当不能确定某个节点的状态时，通过fencing把对方干掉，确保共享资源被 完全释放 透明切换（failover） NameNode切换对外透明，主Namenode切换到另外一台机器时，不应该导致正在连 接的客户端失败，主要包括Client、Datanode与NameNode的链接。 NameNode HA 设计实现主备一致实现 Active NameNode启动后提供服务，并把Editlog写到本地和共享存储中 Standby NameNode周期性的从共享存储中拉取Editlog，保持与active的状态同步 DataNode同时两个NameNode发送BlockReport 脑裂的解决 QJM的fencing，确保只有一个NN能写成功 高可用：QJM全称是Quorum Journal Manager, 由JournalNode（JN）组成，一般是奇数个结点组成。当存活的节点数为偶数个时，无法提供正常服务 基于Paxos：NameNode会同时向所有JournalNode并行写文件，只要有N&#x2F;2+1个结点写成功则认为此次写操作成功，遵循Paxos协议。 防止双写： 这里面涉及一个很重要的概念Epoch Numbers 当NN成为Active结点时，其会被赋予一个Epoch Number 每个Epoch Number是惟一的，不会有相同的出现 Epoch Number有严格顺序保证，每次NN切换后其Epoch Number都会自增1 NN把自己的Epoch Number发送给所有JN结点 NN同步日志到JN的任何RPC请求都必须包含这个Epoch Number JN会对比每次请求中的Epoch Number和保存在本地的Epoch Number，小于则拒绝该请求，反之则更新本地保存的Epoch Number DataNode的fencing，确保只有一个NN能命令DN 每个NN改变状态的时候，向DN发送自己的状态和一个序列号（类似Epoch Numbers） DN在运行过程中维护此序列号，当failover时，新的NN在返回DN心跳时会返回自己的active状态和一个更大的序列号。DN接收到这个返回则认为该NN为新的active 如果这时原来的active NN恢复，返回给DN的心跳信息包含active状态和原来的序列号，这时DN就会拒绝这个NN的命令 客户端fencing，确保只有一个NN能响应客户端请求 让访问Standby NN的客户端直接失败 在RPC层封装了一层，通过FailoverProxyProvider以重试的方式连接NN 通过若干次连接一个NN失败后尝试连接新的NN，对客户端的影响是重试的时候增加一定的延迟 客户端可以设置重试次数和时间 透明切换（failover）主备切换的实现：ZKFC ZKFC即ZKFailoverController，作为独立进程存在，负责控制NameNode的主备切换，ZKFC会监测NameNode的健康状况，当发现Active NameNode出现异常时会通过ZooKeeper集群进行一次主备选举，完成Active和Standby状态的切换。 ZKFC实现下述几个功能 监控NameNode的健康状态。 向ZK定期发送心跳，使自己可以被选举。 当自己被ZK选为主时，active ZKFC使相应的NN转换为active。 HDFS FederationHDFS 1.0命名空间架构 Namespace：由目录、文件和数据块组成，支持常见的文件系统操作，例如创建、删除、修改和列出文件和目录。 Block Storage Service：这个部分又由两部分组成 数据块管理（Block Management），这个模块由NameNode提供 通过处理DataNode的注册和定期心跳来提供集群中DataNode的基本关系； 维护数据到数据块的映射关系，以及数据块在DataNode的映射关系； 支持数据块相关操作，如创建、删除、修改和获取块位置； 管理副本的放置、副本的创建，以及删除多余的副本。 存储（ Storage） - 是由DataNode提供，主要在本地文件系统存储数据块，并提供读写访问。 HDFS Federation设计 NameNode共享底层的数据节点存储资源 DataNode向所有NameNode汇报 属于同一个Namespace的块构成一个block pool 可以存在多个相互独立的NameNode 水平扩展的命名服务 独立管理Namespace和block pool 联邦(Federation)关系不需要彼此协调 向后兼容 HDFS Federation原理 一个Namespace和一个Block Pool对应 一个Block Pool是属于某个namespace下的一系列block。 DataNode是共享的，不同Block Pool的block在同一个DataNode上存储。 一个Namespace和它的block pool一起被叫做Namespace Volume。 HDFS Federation的配置12345678910111213141516171819&lt;!-- core-site.xml --&gt;&lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://nn-host1:rpc-port&lt;/value&gt;&lt;/property&gt;&lt;!-- hdfs-site.xml --&gt;&lt;property&gt; &lt;name&gt;dfs.nameservices&lt;/name&gt; &lt;value&gt;ns1,ns2&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.ns1&lt;/name&gt; &lt;value&gt;nn-host1:rpc-port&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.ns2&lt;/name&gt; &lt;value&gt;nn-host2:rpc-port&lt;/value&gt;&lt;/property&gt; HDFS Federation存在的问题 客户端都要更新配置文件，并维护多个Namespace 访问目录需要指定完整路径 当Namespace增多以后，管理和访问非常不方便 ViewFs（视图文件系统） 基于Federation的问题社区提出了基于客户端的ViewFs ViewFs简单的可以理解为这是一个虚拟的，逻辑上的文件系统 因为这个文件系统实际并不真实存在，只是我们构建了这个文件系统，它的底层指向了实际意义上的多物理集群 ViewFs实际上是使用挂载表（Mount Table）做到的 ViewFs配置123456789101112131415161718192021222324252627&lt;!-- core-site.xml --&gt;&lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;viewfs://Cluster1&lt;/value&gt;&lt;/property&gt;&lt;!-- hdfs-site.xml --&gt;&lt;property&gt; &lt;name&gt;fs.viewfs.mounttable.Cluster1.link./data&lt;/name&gt; &lt;value&gt;hdfs://nn-host1:rpc-port/data&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;fs.viewfs.mounttable.Cluster1.link./project&lt;/name&gt; &lt;value&gt;hdfs://nn-host2:rpc-port/project&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;fs.viewfs.mounttable.Cluster1.link./user&lt;/name&gt; &lt;value&gt;hdfs://nn-host3:rpc-port/user&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;fs.viewfs.mounttable.Cluster1.link./tmp&lt;/name&gt; &lt;value&gt;hdfs://nn-host4:rpc-port/tmp&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;fs.viewfs.mounttable.Cluster1.linkFallback&lt;/name&gt; &lt;value&gt;hdfs://nn-host1:rpc-port/&lt;/value&gt;&lt;/property&gt; ViewFS存在的问题 对于已经发不出去的客户端，升级比较困难； 对于新增目录，需要添加挂在表与产品对接，维护起来比较困难。 HDFS 3.0RBF基于ViewFS的问题，社区在2.9和3.0发布了一个新的解决统一命名空间的方案RBF：Router-Based Federation （HDFS-10467）。该方案是基于服务端实现的，大大简化了升级和管理方面的难度。 基于路由的Federation方案是在服务端添加了一个Federation layer，这个额外的层允许客户端透明地访问任何子集群。Federation layer将Block访问引导至适当的子群集，维护namespaces的状态。Federation layer包含多个组件。Router是一个与NameNode具有相同接口的组件，根据State Store的元数据信息将客户端请求转发给正确的子集群。StateStore组件包含了远程挂载表（和ViewFS方案里面的配置文件类似，但在客户端之间共享）。 主要组件介绍 Router（无状态） 一个系统中可以包含多个Router，每个Router包含两个作用： 为客户端提供单个全局的NameNode接口，并将客户端的请求转发到正确子集群中的Active NameNode 上。 收集NameNode的心跳信息，报告给State Store，这样State Store维护的信息是实时更新的。 State Store（ 分布式） 在State Store里面主要维护以下几方面的信息： 子集群的状态，包括块访问负载、可用磁盘空间、HA状态等； 文件夹&#x2F;文件和子集群之间的映射，即远程挂载表； Rebalancer操作的状态； Routers的状态。 RBF访问流程 客户端向集群中任意一个Router发出某个文件的读写请求操作； Router从State Store里面的Mount Table查询哪个子集群包含这个文件，并从State Store里面的Membership table里面获取正确的NN； Router获取到正确的NN后，会将客户端的请求转发到NN上，然后也会给客户端一个请求告诉它需要请求哪个子集群； 此后，客户端就可以直接访问对应子集群的DN，并进行读写相关的操作。 总结 HDFS的Master&#x2F;Slave架构，使得Master节点在元数据存储与提供服务上都会存在瓶颈。 为了解决扩展性、性能、隔离等问题，社区提出了Federation方案（HDFS-1052）。 使用该方案之后，带来的问题就是同一个集群出现了多个命名空间（namespace）。客户需要知道读写的数据在哪个命名空间下才可以进行操作。为了解决统一命名空间的问题，社区提出了基于客户端（client-side）的解决方案ViewFS（HADOOP-7257）。 ViewFS同样也存在一些问题，例如对于已经发布出去客户端升级比较困难，、对于新增目录需要增加挂载配置，维护起来比较困难。社区在2.9和3.0版本中发布了一个新的解决统一命名空间问题的方案Router-Based Federation（HDFS-10467），该方案是基于服务端进行实现的。","categories":[{"name":"大数据","slug":"大数据","permalink":"http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"hadoop","slug":"大数据/hadoop","permalink":"http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/hadoop/"}],"tags":[]},{"title":"jvm内存模型","slug":"jvm/jvm内存模型","date":"2022-08-05T15:59:40.000Z","updated":"2022-08-05T16:00:47.665Z","comments":true,"path":"2022/08/05/jvm/jvm内存模型/","link":"","permalink":"http://example.com/2022/08/05/jvm/jvm%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/","excerpt":"","text":"","categories":[{"name":"JVM","slug":"JVM","permalink":"http://example.com/categories/JVM/"},{"name":"内存模型","slug":"JVM/内存模型","permalink":"http://example.com/categories/JVM/%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/"}],"tags":[]},{"title":"tidb","slug":"大数据/tidb","date":"2022-08-05T15:59:19.000Z","updated":"2022-08-05T16:00:47.642Z","comments":true,"path":"2022/08/05/大数据/tidb/","link":"","permalink":"http://example.com/2022/08/05/%E5%A4%A7%E6%95%B0%E6%8D%AE/tidb/","excerpt":"","text":"","categories":[{"name":"大数据","slug":"大数据","permalink":"http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"TiDB","slug":"大数据/TiDB","permalink":"http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/TiDB/"}],"tags":[]},{"title":"nio","slug":"IO/nio","date":"2022-08-05T15:57:33.000Z","updated":"2022-08-05T15:58:54.655Z","comments":true,"path":"2022/08/05/IO/nio/","link":"","permalink":"http://example.com/2022/08/05/IO/nio/","excerpt":"","text":"","categories":[{"name":"IO","slug":"IO","permalink":"http://example.com/categories/IO/"},{"name":"nio","slug":"IO/nio","permalink":"http://example.com/categories/IO/nio/"}],"tags":[]},{"title":"bio","slug":"IO/bio","date":"2022-08-05T15:57:30.000Z","updated":"2022-08-05T15:58:54.652Z","comments":true,"path":"2022/08/05/IO/bio/","link":"","permalink":"http://example.com/2022/08/05/IO/bio/","excerpt":"","text":"","categories":[{"name":"IO","slug":"IO","permalink":"http://example.com/categories/IO/"},{"name":"bio","slug":"IO/bio","permalink":"http://example.com/categories/IO/bio/"}],"tags":[]},{"title":"aio","slug":"IO/aio","date":"2022-08-05T15:57:27.000Z","updated":"2022-08-05T15:58:54.650Z","comments":true,"path":"2022/08/05/IO/aio/","link":"","permalink":"http://example.com/2022/08/05/IO/aio/","excerpt":"","text":"","categories":[{"name":"IO","slug":"IO","permalink":"http://example.com/categories/IO/"},{"name":"aio","slug":"IO/aio","permalink":"http://example.com/categories/IO/aio/"}],"tags":[]},{"title":"dubbo","slug":"RPC/dubbo","date":"2022-08-05T15:57:09.000Z","updated":"2022-08-05T15:58:54.648Z","comments":true,"path":"2022/08/05/RPC/dubbo/","link":"","permalink":"http://example.com/2022/08/05/RPC/dubbo/","excerpt":"","text":"","categories":[{"name":"RPC","slug":"RPC","permalink":"http://example.com/categories/RPC/"},{"name":"dubbo","slug":"RPC/dubbo","permalink":"http://example.com/categories/RPC/dubbo/"}],"tags":[]},{"title":"ClickHouse","slug":"大数据/ClickHouse","date":"2022-08-05T15:55:35.000Z","updated":"2022-08-05T15:56:01.953Z","comments":true,"path":"2022/08/05/大数据/ClickHouse/","link":"","permalink":"http://example.com/2022/08/05/%E5%A4%A7%E6%95%B0%E6%8D%AE/ClickHouse/","excerpt":"","text":"","categories":[{"name":"大数据","slug":"大数据","permalink":"http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"ClickHouse","slug":"大数据/ClickHouse","permalink":"http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/ClickHouse/"}],"tags":[]},{"title":"Mybatis","slug":"框架/Mybatis","date":"2022-08-05T15:54:03.000Z","updated":"2022-08-05T15:54:22.487Z","comments":true,"path":"2022/08/05/框架/Mybatis/","link":"","permalink":"http://example.com/2022/08/05/%E6%A1%86%E6%9E%B6/Mybatis/","excerpt":"","text":"","categories":[{"name":"框架","slug":"框架","permalink":"http://example.com/categories/%E6%A1%86%E6%9E%B6/"},{"name":"Mybatis","slug":"框架/Mybatis","permalink":"http://example.com/categories/%E6%A1%86%E6%9E%B6/Mybatis/"}],"tags":[]},{"title":"SpringCloud","slug":"框架/SpringCloud","date":"2022-08-05T15:53:07.000Z","updated":"2022-08-05T15:53:57.979Z","comments":true,"path":"2022/08/05/框架/SpringCloud/","link":"","permalink":"http://example.com/2022/08/05/%E6%A1%86%E6%9E%B6/SpringCloud/","excerpt":"","text":"","categories":[{"name":"框架","slug":"框架","permalink":"http://example.com/categories/%E6%A1%86%E6%9E%B6/"},{"name":"SpringCloud","slug":"框架/SpringCloud","permalink":"http://example.com/categories/%E6%A1%86%E6%9E%B6/SpringCloud/"}],"tags":[]},{"title":"SpringBoot","slug":"框架/SpringBoot","date":"2022-08-05T15:53:02.000Z","updated":"2022-08-05T15:53:57.977Z","comments":true,"path":"2022/08/05/框架/SpringBoot/","link":"","permalink":"http://example.com/2022/08/05/%E6%A1%86%E6%9E%B6/SpringBoot/","excerpt":"","text":"","categories":[{"name":"框架","slug":"框架","permalink":"http://example.com/categories/%E6%A1%86%E6%9E%B6/"},{"name":"SpringBoot","slug":"框架/SpringBoot","permalink":"http://example.com/categories/%E6%A1%86%E6%9E%B6/SpringBoot/"}],"tags":[]},{"title":"Spring","slug":"框架/Spring","date":"2022-08-05T15:52:58.000Z","updated":"2022-08-05T15:53:57.974Z","comments":true,"path":"2022/08/05/框架/Spring/","link":"","permalink":"http://example.com/2022/08/05/%E6%A1%86%E6%9E%B6/Spring/","excerpt":"","text":"","categories":[{"name":"框架","slug":"框架","permalink":"http://example.com/categories/%E6%A1%86%E6%9E%B6/"},{"name":"Spring","slug":"框架/Spring","permalink":"http://example.com/categories/%E6%A1%86%E6%9E%B6/Spring/"}],"tags":[]},{"title":"Paxos","slug":"分布式/分布式协议/Paxos","date":"2022-08-05T15:50:39.000Z","updated":"2022-08-05T15:51:33.726Z","comments":true,"path":"2022/08/05/分布式/分布式协议/Paxos/","link":"","permalink":"http://example.com/2022/08/05/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E8%AE%AE/Paxos/","excerpt":"","text":"","categories":[{"name":"分布式","slug":"分布式","permalink":"http://example.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"分布式协议","slug":"分布式/分布式协议","permalink":"http://example.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E8%AE%AE/"}],"tags":[]},{"title":"BASE","slug":"分布式/分布式协议/BASE","date":"2022-08-05T15:50:17.000Z","updated":"2022-08-05T15:51:33.718Z","comments":true,"path":"2022/08/05/分布式/分布式协议/BASE/","link":"","permalink":"http://example.com/2022/08/05/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E8%AE%AE/BASE/","excerpt":"","text":"","categories":[{"name":"分布式","slug":"分布式","permalink":"http://example.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"分布式协议","slug":"分布式/分布式协议","permalink":"http://example.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E8%AE%AE/"}],"tags":[]},{"title":"ACID","slug":"分布式/分布式协议/ACID","date":"2022-08-05T15:50:06.000Z","updated":"2022-08-05T15:51:33.713Z","comments":true,"path":"2022/08/05/分布式/分布式协议/ACID/","link":"","permalink":"http://example.com/2022/08/05/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E8%AE%AE/ACID/","excerpt":"","text":"","categories":[{"name":"分布式","slug":"分布式","permalink":"http://example.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"分布式协议","slug":"分布式/分布式协议","permalink":"http://example.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E8%AE%AE/"}],"tags":[]},{"title":"CAP","slug":"分布式/分布式协议/CAP","date":"2022-08-05T15:49:58.000Z","updated":"2022-08-05T15:51:33.722Z","comments":true,"path":"2022/08/05/分布式/分布式协议/CAP/","link":"","permalink":"http://example.com/2022/08/05/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E8%AE%AE/CAP/","excerpt":"","text":"","categories":[{"name":"分布式","slug":"分布式","permalink":"http://example.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"分布式协议","slug":"分布式/分布式协议","permalink":"http://example.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E8%AE%AE/"}],"tags":[]},{"title":"拜占庭将军问题","slug":"分布式/分布式协议/拜占庭将军问题","date":"2022-08-05T15:49:44.000Z","updated":"2022-08-05T15:51:33.729Z","comments":true,"path":"2022/08/05/分布式/分布式协议/拜占庭将军问题/","link":"","permalink":"http://example.com/2022/08/05/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E8%AE%AE/%E6%8B%9C%E5%8D%A0%E5%BA%AD%E5%B0%86%E5%86%9B%E9%97%AE%E9%A2%98/","excerpt":"","text":"","categories":[{"name":"分布式","slug":"分布式","permalink":"http://example.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"分布式协议","slug":"分布式/分布式协议","permalink":"http://example.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E8%AE%AE/"}],"tags":[]},{"title":"垃圾回收","slug":"jvm/垃圾回收","date":"2022-08-05T15:40:00.000Z","updated":"2022-08-05T15:43:13.477Z","comments":true,"path":"2022/08/05/jvm/垃圾回收/","link":"","permalink":"http://example.com/2022/08/05/jvm/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/","excerpt":"","text":"","categories":[{"name":"JVM","slug":"JVM","permalink":"http://example.com/categories/JVM/"},{"name":"垃圾回收","slug":"JVM/垃圾回收","permalink":"http://example.com/categories/JVM/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/"}],"tags":[]},{"title":"类加载机制","slug":"jvm/类加载机制","date":"2022-08-05T15:39:52.000Z","updated":"2022-08-05T15:43:13.473Z","comments":true,"path":"2022/08/05/jvm/类加载机制/","link":"","permalink":"http://example.com/2022/08/05/jvm/%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/","excerpt":"","text":"","categories":[{"name":"JVM","slug":"JVM","permalink":"http://example.com/categories/JVM/"},{"name":"类加载机制","slug":"JVM/类加载机制","permalink":"http://example.com/categories/JVM/%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/"}],"tags":[]},{"title":"ddd","slug":"DDD/ddd","date":"2022-08-05T15:39:08.000Z","updated":"2022-08-05T15:39:38.266Z","comments":true,"path":"2022/08/05/DDD/ddd/","link":"","permalink":"http://example.com/2022/08/05/DDD/ddd/","excerpt":"","text":"","categories":[{"name":"DDD","slug":"DDD","permalink":"http://example.com/categories/DDD/"}],"tags":[]},{"title":"mysql","slug":"存储/mysql","date":"2022-08-05T15:35:33.000Z","updated":"2022-08-05T15:47:12.623Z","comments":true,"path":"2022/08/05/存储/mysql/","link":"","permalink":"http://example.com/2022/08/05/%E5%AD%98%E5%82%A8/mysql/","excerpt":"","text":"","categories":[{"name":"存储","slug":"存储","permalink":"http://example.com/categories/%E5%AD%98%E5%82%A8/"},{"name":"mysql","slug":"存储/mysql","permalink":"http://example.com/categories/%E5%AD%98%E5%82%A8/mysql/"}],"tags":[]},{"title":"zk","slug":"中间件/zk","date":"2022-08-05T15:34:53.000Z","updated":"2022-08-05T15:37:43.371Z","comments":true,"path":"2022/08/05/中间件/zk/","link":"","permalink":"http://example.com/2022/08/05/%E4%B8%AD%E9%97%B4%E4%BB%B6/zk/","excerpt":"","text":"","categories":[{"name":"中间件","slug":"中间件","permalink":"http://example.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"zk","slug":"中间件/zk","permalink":"http://example.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/zk/"}],"tags":[]},{"title":"es","slug":"中间件/es","date":"2022-08-05T15:33:46.000Z","updated":"2022-08-05T15:37:43.365Z","comments":true,"path":"2022/08/05/中间件/es/","link":"","permalink":"http://example.com/2022/08/05/%E4%B8%AD%E9%97%B4%E4%BB%B6/es/","excerpt":"","text":"","categories":[{"name":"中间件","slug":"中间件","permalink":"http://example.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"es","slug":"中间件/es","permalink":"http://example.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/es/"}],"tags":[]},{"title":"kafka","slug":"中间件/kafka","date":"2022-08-05T15:33:33.000Z","updated":"2022-08-05T15:37:43.360Z","comments":true,"path":"2022/08/05/中间件/kafka/","link":"","permalink":"http://example.com/2022/08/05/%E4%B8%AD%E9%97%B4%E4%BB%B6/kafka/","excerpt":"","text":"","categories":[{"name":"中间件","slug":"中间件","permalink":"http://example.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"kafka","slug":"中间件/kafka","permalink":"http://example.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/kafka/"}],"tags":[]},{"title":"redis","slug":"中间件/redis","date":"2022-08-05T15:30:03.000Z","updated":"2022-08-05T15:37:43.362Z","comments":true,"path":"2022/08/05/中间件/redis/","link":"","permalink":"http://example.com/2022/08/05/%E4%B8%AD%E9%97%B4%E4%BB%B6/redis/","excerpt":"","text":"","categories":[{"name":"中间件","slug":"中间件","permalink":"http://example.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"redis","slug":"中间件/redis","permalink":"http://example.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/redis/"}],"tags":[]},{"title":"flink","slug":"大数据/flink","date":"2022-08-05T15:28:56.000Z","updated":"2022-08-05T15:29:28.454Z","comments":true,"path":"2022/08/05/大数据/flink/","link":"","permalink":"http://example.com/2022/08/05/%E5%A4%A7%E6%95%B0%E6%8D%AE/flink/","excerpt":"","text":"","categories":[{"name":"大数据","slug":"大数据","permalink":"http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"flink","slug":"大数据/flink","permalink":"http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/flink/"}],"tags":[]},{"title":"spark","slug":"大数据/spark","date":"2022-08-05T15:28:48.000Z","updated":"2022-08-05T15:29:28.457Z","comments":true,"path":"2022/08/05/大数据/spark/","link":"","permalink":"http://example.com/2022/08/05/%E5%A4%A7%E6%95%B0%E6%8D%AE/spark/","excerpt":"","text":"","categories":[{"name":"大数据","slug":"大数据","permalink":"http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"spark","slug":"大数据/spark","permalink":"http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/spark/"}],"tags":[]},{"title":"Hadoop简介","slug":"大数据/hadoop/Hadoop简介","date":"2022-08-05T15:26:00.000Z","updated":"2022-08-06T01:38:04.830Z","comments":true,"path":"2022/08/05/大数据/hadoop/Hadoop简介/","link":"","permalink":"http://example.com/2022/08/05/%E5%A4%A7%E6%95%B0%E6%8D%AE/hadoop/Hadoop%E7%AE%80%E4%BB%8B/","excerpt":"","text":"Hadoop简介 Hadoop是Apache的一个开源的分布式计算平台，核心是以HDFS分布式文件系统和MapReduce分布式计算框架构成，为用户提供了一套底层透明的分布式基础设施 Hadoop框架中最核心设计就是：HDFS和MapReduce。HDFS提供了海量数据的存储,MapReduce提供了对数据的计算。 HDFS是Hadoop分布式文件系统，具有高容错性、高伸缩性，允许用户基于廉价硬件部署，构建分布式存储系统，为分布式计算存储提供了底层支持 MapReduce提供简单的API，允许用户在不了解底层细节的情况下，开发分布式并行程序，利用大规模集群资源，解决传统单机无法解决的大数据处理问题 设计思想起源于Google GFS、MapReduce Paper Doug Cutting在Yahoo开发，2008年贡献给Apache基金会 Hadoop项目组件","categories":[{"name":"大数据","slug":"大数据","permalink":"http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"hadoop","slug":"大数据/hadoop","permalink":"http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/hadoop/"}],"tags":[]},{"title":"标签","slug":"用户画像/标签","date":"2022-08-05T08:26:36.000Z","updated":"2022-08-06T00:25:35.852Z","comments":true,"path":"2022/08/05/用户画像/标签/","link":"","permalink":"http://example.com/2022/08/05/%E7%94%A8%E6%88%B7%E7%94%BB%E5%83%8F/%E6%A0%87%E7%AD%BE/","excerpt":"","text":"","categories":[{"name":"用户画像","slug":"用户画像","permalink":"http://example.com/categories/%E7%94%A8%E6%88%B7%E7%94%BB%E5%83%8F/"},{"name":"标签","slug":"用户画像/标签","permalink":"http://example.com/categories/%E7%94%A8%E6%88%B7%E7%94%BB%E5%83%8F/%E6%A0%87%E7%AD%BE/"}],"tags":[]}],"categories":[{"name":"大数据","slug":"大数据","permalink":"http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"hadoop","slug":"大数据/hadoop","permalink":"http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/hadoop/"},{"name":"系统设计","slug":"系统设计","permalink":"http://example.com/categories/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"},{"name":"分布式","slug":"分布式","permalink":"http://example.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"分布式锁","slug":"分布式/分布式锁","permalink":"http://example.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/"},{"name":"分布式事务","slug":"分布式/分布式事务","permalink":"http://example.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/"},{"name":"分布式缓存","slug":"分布式/分布式缓存","permalink":"http://example.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98/"},{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"算法","slug":"算法","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/"},{"name":"动态规划","slug":"算法/动态规划","permalink":"http://example.com/categories/%E7%AE%97%E6%B3%95/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"},{"name":"框架","slug":"框架","permalink":"http://example.com/categories/%E6%A1%86%E6%9E%B6/"},{"name":"Netty","slug":"框架/Netty","permalink":"http://example.com/categories/%E6%A1%86%E6%9E%B6/Netty/"},{"name":"JVM","slug":"JVM","permalink":"http://example.com/categories/JVM/"},{"name":"内存模型","slug":"JVM/内存模型","permalink":"http://example.com/categories/JVM/%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/"},{"name":"TiDB","slug":"大数据/TiDB","permalink":"http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/TiDB/"},{"name":"IO","slug":"IO","permalink":"http://example.com/categories/IO/"},{"name":"nio","slug":"IO/nio","permalink":"http://example.com/categories/IO/nio/"},{"name":"bio","slug":"IO/bio","permalink":"http://example.com/categories/IO/bio/"},{"name":"aio","slug":"IO/aio","permalink":"http://example.com/categories/IO/aio/"},{"name":"RPC","slug":"RPC","permalink":"http://example.com/categories/RPC/"},{"name":"dubbo","slug":"RPC/dubbo","permalink":"http://example.com/categories/RPC/dubbo/"},{"name":"ClickHouse","slug":"大数据/ClickHouse","permalink":"http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/ClickHouse/"},{"name":"Mybatis","slug":"框架/Mybatis","permalink":"http://example.com/categories/%E6%A1%86%E6%9E%B6/Mybatis/"},{"name":"SpringCloud","slug":"框架/SpringCloud","permalink":"http://example.com/categories/%E6%A1%86%E6%9E%B6/SpringCloud/"},{"name":"SpringBoot","slug":"框架/SpringBoot","permalink":"http://example.com/categories/%E6%A1%86%E6%9E%B6/SpringBoot/"},{"name":"Spring","slug":"框架/Spring","permalink":"http://example.com/categories/%E6%A1%86%E6%9E%B6/Spring/"},{"name":"分布式协议","slug":"分布式/分布式协议","permalink":"http://example.com/categories/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E8%AE%AE/"},{"name":"垃圾回收","slug":"JVM/垃圾回收","permalink":"http://example.com/categories/JVM/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/"},{"name":"类加载机制","slug":"JVM/类加载机制","permalink":"http://example.com/categories/JVM/%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/"},{"name":"DDD","slug":"DDD","permalink":"http://example.com/categories/DDD/"},{"name":"存储","slug":"存储","permalink":"http://example.com/categories/%E5%AD%98%E5%82%A8/"},{"name":"mysql","slug":"存储/mysql","permalink":"http://example.com/categories/%E5%AD%98%E5%82%A8/mysql/"},{"name":"中间件","slug":"中间件","permalink":"http://example.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"zk","slug":"中间件/zk","permalink":"http://example.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/zk/"},{"name":"es","slug":"中间件/es","permalink":"http://example.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/es/"},{"name":"kafka","slug":"中间件/kafka","permalink":"http://example.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/kafka/"},{"name":"redis","slug":"中间件/redis","permalink":"http://example.com/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/redis/"},{"name":"flink","slug":"大数据/flink","permalink":"http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/flink/"},{"name":"spark","slug":"大数据/spark","permalink":"http://example.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/spark/"},{"name":"用户画像","slug":"用户画像","permalink":"http://example.com/categories/%E7%94%A8%E6%88%B7%E7%94%BB%E5%83%8F/"},{"name":"标签","slug":"用户画像/标签","permalink":"http://example.com/categories/%E7%94%A8%E6%88%B7%E7%94%BB%E5%83%8F/%E6%A0%87%E7%AD%BE/"}],"tags":[]}